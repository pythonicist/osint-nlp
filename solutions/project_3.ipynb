{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Project 3\n",
    "```text\n",
    "- Source: SEC\n",
    "- Goal: Extract information from HTML tables\n",
    "- Techniques: HTML parsing, NER, Dataframes\n",
    "- Tools: Beautifulsoup, pandas, spacy\n",
    "- Lines of code: ~100```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import datetime\n",
    "\n",
    "# Third-party\n",
    "import re\n",
    "import spacy\n",
    "import requests\n",
    "import pandas as pd\n",
    "from lxml import html, etree\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "\n",
    "NLP = spacy.load('en_core_web_sm')\n",
    "\n",
    "def parse(table):\n",
    "    new_table = BeautifulSoup(table, 'html.parser')\n",
    "    row_ind, col_ind = 0, 0\n",
    "    output = []\n",
    "    for row in new_table.find_all('tr'):\n",
    "        smallest_row_span = 1\n",
    "        for cell in row.children:\n",
    "            if cell.name in ('td', 'th'):\n",
    "                span = cell.get('rowspan')\n",
    "                row_span = int(span) if span else 1\n",
    "                smallest_row_span = min(smallest_row_span, row_span)\n",
    "                span = cell.get('colspan')\n",
    "                col_span = int(span) if span else 1\n",
    "                while True:\n",
    "                    if row_ind >= len(output) or \\\n",
    "                            col_ind >= len(output[row_ind]) \\\n",
    "                            or output[row_ind][col_ind] is None:\n",
    "                        break\n",
    "                    col_ind += 1\n",
    "                for ii in range(row_ind, row_ind + row_span):\n",
    "                    for jj in range(col_ind, col_ind + col_span):\n",
    "                        while ii >= len(output):\n",
    "                            output.append([])\n",
    "                        while jj >= len(output[ii]):\n",
    "                            output[ii].append(None)\n",
    "                        if output[ii][jj] is None:\n",
    "                            output[ii][jj] = str(cell.get_text())\n",
    "                col_ind += col_span\n",
    "        row_ind += smallest_row_span\n",
    "        col_ind = 0\n",
    "    return output\n",
    "\n",
    "def get_tables_from_url(url):\n",
    "    res = requests.get(url)\n",
    "    tree = html.fromstring(res.content)\n",
    "    return tree.xpath('//table')\n",
    "\n",
    "def parse_comp_tables(tables):\n",
    "    dfs = []\n",
    "    for table in tables:\n",
    "        table_string = re.sub(r'<br/?>', '\\n', str(etree.tostring(table)), \n",
    "                              flags=re.DOTALL)\n",
    "        parsed_tables = parse(table_string)\n",
    "        parsed = [[i.replace('\\xa0', ' ').strip() for i in j] for j in \n",
    "                  parsed_tables]\n",
    "        parsed = [i for i in parsed if any(bool(j) for j in i)]\n",
    "        if parsed and parsed[0] and re.findall(r'^name', parsed[0][0], \n",
    "                                               flags=re.IGNORECASE|re.DOTALL):\n",
    "            parsed[0] = [' '.join(i.split()).strip() for i in parsed[0]]\n",
    "            parsed[0] = [i.replace('\\\\n', ' ').strip() for i in parsed[0]]\n",
    "            parsed[1:] = [[i.replace(r'\\n', ', ').strip() for i in j] \n",
    "                          for j in parsed[1:]]\n",
    "            parsed = [[i if i else None for i in j] for j in parsed]\n",
    "            df = pd.DataFrame(parsed[1:], columns=parsed[0])\n",
    "            if df.ix[:,0].iloc[0].replace(',', '') == df.columns[0]:\n",
    "                df = df.iloc[1:]\n",
    "            df = df.dropna(axis=1, how='all')\n",
    "            df.columns = ['Name'] + df.columns.values.tolist()[1:]\n",
    "            dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "def clean_tables(dfs):\n",
    "    mapping = {None: None}\n",
    "\n",
    "    for df in dfs:\n",
    "        for name in df['Name'].values:\n",
    "            if name is None:\n",
    "                continue\n",
    "            clean = re.sub(r'\\d+', '', name)\n",
    "            ents = [i.text for i in NLP(clean).ents if i.label_ == 'PERSON']\n",
    "            if not ents: ents = [name]\n",
    "            mapping[name] = ents[0]\n",
    "\n",
    "    for num, df in enumerate(dfs):\n",
    "        df['Name'] = df['Name'].apply(lambda x: mapping[x])\n",
    "        for num, row in enumerate(df.iterrows()):\n",
    "            if row[1]['Name'] is None and num > 0:\n",
    "                df.iloc[num]['Name'] = df.iloc[num - 1]['Name']\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "urls = [\n",
    "    '789019/000119312517310951/d461626ddef14a.htm',\n",
    "    '320193/000119312516422528/d79474ddef14a.htm'\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    full_url = 'https://www.sec.gov/Archives/edgar/data/%s' % url \n",
    "    tables = get_tables_from_url(full_url)\n",
    "    dfs = parse_comp_tables(tables)\n",
    "    dfs = clean_tables(dfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
